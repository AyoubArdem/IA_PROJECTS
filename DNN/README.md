

# üå¶Ô∏è Rainfall Prediction Project

##  Description
Ce projet a pour objectif de **pr√©dire la probabilit√© de pluie** √† partir de donn√©es m√©t√©orologiques (pression, temp√©rature, humidit√©, nuages, etc.).  
Il utilise des techniques de **pr√©traitement des donn√©es**, de **r√©√©chantillonnage pour √©quilibrer les classes**, et un **mod√®le de r√©seau de neurones (TensorFlow/Keras)** pour effectuer la classification binaire (`rainfall = yes/no`).



##  Structure du projet
- `Rainfall.csv` : dataset brut contenant les observations m√©t√©orologiques.
- `notebook/code.py` : script principal avec toutes les √©tapes (pr√©traitement, entra√Ænement, √©valuation).
- `README.md` : documentation du projet.



##  √âtapes principales

### 1. Pr√©traitement des donn√©es
- Nettoyage des colonnes (`strip`, gestion des valeurs manquantes).
- Conversion de la variable cible `rainfall` en labels num√©riques (`yes ‚Üí 1`, `no ‚Üí 0`).
- Suppression des colonnes peu pertinentes (`day`, `winddirection`, `mintemp`, `maxtemp`).
- Normalisation des features avec `StandardScaler`.

### 2. √âquilibrage des classes
- Utilisation de **resampling** (`sklearn.utils.resample`) pour √©quilibrer les classes `yes` et `no`.

### 3. Analyse exploratoire
- Visualisation des distributions avec `seaborn` et `matplotlib`.
- Matrice de corr√©lation et heatmap pour identifier les variables les plus li√©es √† la pluie.

### 4. Mod√©lisation
- R√©seau de neurones avec **Keras Sequential** :
  ```python
  model = tf.keras.Sequential([
      tf.keras.layers.Input(shape=(x_train.shape[1],)),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(1, activation='sigmoid')
  ])
  ```
- Compilation :
  ```python
  model.compile(optimizer='adam',
                loss='binary_crossentropy',
                metrics=['accuracy'])
  ```
- Callbacks :
  - `EarlyStopping` pour √©viter l‚Äôoverfitting.

### 5. √âvaluation
- Courbes `loss` et `accuracy` (train/validation).


##  R√©sultats attendus
- Une **loss positive** qui diminue progressivement.
- Une **accuracy** qui s‚Äôam√©liore au fil des epochs (>80% selon la qualit√© des donn√©es).
- Visualisation des performances pour interpr√©ter la convergence du mod√®le.


##  Technologies utilis√©es
- **Python 3**
- **Pandas / NumPy** : manipulation des donn√©es
- **Matplotlib / Seaborn** : visualisation
- **Scikit-learn** : preprocessing, resampling, split
- **TensorFlow / Keras** : mod√©lisation et entra√Ænement
